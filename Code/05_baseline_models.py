# 05_baseline_models.py
# åŸºçº¿æ¨¡å‹å¯¹æ¯” - åŒ…å«TMH-OMPæ¨¡å‹

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.linear_model import LinearRegression, PoissonRegressor
from sklearn.ensemble import RandomForestRegressor, VotingRegressor
import xgboost as xgb
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

print("="*80)
print("å¥¥è¿å¥–ç‰Œé¢„æµ‹ - åŸºçº¿æ¨¡å‹å¯¹æ¯”")
print("Olympic Medal Prediction - Baseline Models Comparison")
print("="*80)
print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

# ============================================================================
# Part 1: æ•°æ®åŠ è½½ä¸å‡†å¤‡
# ============================================================================

print("\n" + "="*80)
print("Part 1: æ•°æ®åŠ è½½ä¸å‡†å¤‡")
print("="*80)

# åŠ è½½ç‰¹å¾å·¥ç¨‹åçš„æ•°æ®
df = pd.read_csv('Cleaned_Data/master_data_with_features.csv')

print(f"âœ“ åŠ è½½æ•°æ®: {len(df):,} è¡Œ Ã— {len(df.columns)} åˆ—")
print(f"  å¹´ä»½èŒƒå›´: {df['Year'].min()} - {df['Year'].max()}")
print(f"  å›½å®¶æ•°: {df['NOC'].nunique()}")

# åŠ è½½è¿åŠ¨å‘˜æ•°æ®ï¼ˆç”¨äºè®¡ç®—NA - å‚ä¸è€…æ•°é‡ï¼‰
df_athletes = pd.read_csv('Original Data/summerOly_athletes.csv')
print(f"âœ“ åŠ è½½è¿åŠ¨å‘˜æ•°æ®: {len(df_athletes):,} è¡Œ")

# ============================================================================
# Part 2: æ·»åŠ TMH-OMPæ¨¡å‹éœ€è¦çš„å˜é‡
# ============================================================================

print("\n" + "="*80)
print("Part 2: å‡†å¤‡TMH-OMPæ¨¡å‹å˜é‡")
print("="*80)

print("\nè®¡ç®—æ¯ä¸ªå›½å®¶æ¯å¹´çš„è¿åŠ¨å‘˜æ•°é‡ (NA)...")
# è®¡ç®—æ¯ä¸ªå›½å®¶æ¯å¹´çš„è¿åŠ¨å‘˜æ•°é‡
athlete_counts = df_athletes.groupby(['Year', 'NOC']).agg({
    'Name': 'nunique'  # å”¯ä¸€è¿åŠ¨å‘˜æ•°é‡
}).reset_index()
athlete_counts.columns = ['Year', 'NOC', 'Num_Athletes']

# åˆå¹¶åˆ°ä¸»æ•°æ®
df = df.merge(athlete_counts, on=['Year', 'NOC'], how='left')
df['Num_Athletes'] = df['Num_Athletes'].fillna(0)

print(f"âœ“ å·²æ·»åŠ  Num_Athletes (NA)")
print(f"  å¹³å‡è¿åŠ¨å‘˜æ•°: {df['Num_Athletes'].mean():.1f}")
print(f"  æœ€å¤§è¿åŠ¨å‘˜æ•°: {df['Num_Athletes'].max():.0f}")

# è®¡ç®—äº‹ä»¶å‚ä¸ç‡ (ER) - å·²ç»æœ‰äº†ï¼Œä½†ç¡®ä¿å­˜åœ¨
if 'Total_Events' not in df.columns:
    print("âš ï¸ è­¦å‘Š: Total_Eventsä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å€¼")
    df['Total_Events'] = 300  # é»˜è®¤å€¼

# è®¡ç®—Mundlakä¿®æ­£éœ€è¦çš„æ—¶é—´å¹³å‡å€¼
print("\nè®¡ç®—Mundlakä¿®æ­£çš„æ—¶é—´å¹³å‡ç‰¹å¾...")
mundlak_vars = ['Gold', 'Total', 'is_host', 'Total_Events', 'Num_Athletes']

for var in mundlak_vars:
    if var in df.columns:
        # è®¡ç®—æ¯ä¸ªå›½å®¶çš„æ—¶é—´å¹³å‡å€¼
        country_means = df.groupby('NOC')[var].transform('mean')
        df[f'{var}_mean'] = country_means
        print(f"  âœ“ {var}_mean")

# åˆ›å»ºå›½å®¶ç¼–ç ï¼ˆç”¨äºå›ºå®šæ•ˆåº”ï¼‰
from sklearn.preprocessing import LabelEncoder
le_noc = LabelEncoder()
df['NOC_encoded'] = le_noc.fit_transform(df['NOC'])

print(f"\nâœ“ TMH-OMPå˜é‡å‡†å¤‡å®Œæˆ")
print(f"  å›½å®¶æ•°: {df['NOC'].nunique()}")
print(f"  å›½å®¶ç¼–ç èŒƒå›´: 0-{df['NOC_encoded'].max()}")

# ============================================================================
# Part 3: æ•°æ®åˆ†å‰²
# ============================================================================

print("\n" + "="*80)
print("Part 3: æ•°æ®åˆ†å‰² (Train/Val/Test)")
print("="*80)

# å®šä¹‰ç›®æ ‡å˜é‡
target_col = 'Gold'

# å®šä¹‰ç‰¹å¾åˆ—
base_features = [
    'Gold_lag1', 'Gold_lag2', 'Gold_lag3',
    'Gold_rolling_mean_3', 'Gold_rolling_mean_5',
    'Gold_rolling_std_3',
    'Gold_growth_rate', 'Gold_change',
    'is_host', 'Total_Events', 
    'Market_Share_Gold',
    'olympic_experience',
    'gold_percentile',
    'Gold_host_boost',
    'Num_Athletes'
]

# TMH-OMPé¢å¤–éœ€è¦çš„ç‰¹å¾
tmh_features = base_features + [
    'Gold_mean', 'Total_mean', 'is_host_mean', 
    'Total_Events_mean', 'Num_Athletes_mean',
    'NOC_encoded'
]

# ç§»é™¤ä¸å­˜åœ¨çš„ç‰¹å¾
base_features = [f for f in base_features if f in df.columns]
tmh_features = [f for f in tmh_features if f in df.columns]

print(f"\nåŸºç¡€ç‰¹å¾æ•°: {len(base_features)}")
print(f"TMH-OMPç‰¹å¾æ•°: {len(tmh_features)}")

# æŒ‰æ—¶é—´åˆ†å‰²æ•°æ®
# Train: 1896-2016, Val: 2020, Test: 2024
df_train = df[df['Year'] <= 2016].copy()
df_val = df[df['Year'] == 2020].copy()
df_test = df[df['Year'] == 2024].copy()

print(f"\næ•°æ®åˆ†å‰²:")
print(f"  è®­ç»ƒé›†: {len(df_train):,} è¡Œ (1896-2016)")
print(f"  éªŒè¯é›†: {len(df_val):,} è¡Œ (2020)")
print(f"  æµ‹è¯•é›†: {len(df_test):,} è¡Œ (2024)")

# å‡†å¤‡è®­ç»ƒæ•°æ®ï¼ˆå¤„ç†ç¼ºå¤±å€¼ï¼‰
print(f"\nå¤„ç†ç¼ºå¤±å€¼...")

# å¯¹äºåŸºç¡€ç‰¹å¾ï¼Œç”¨0å¡«å……ï¼ˆè¡¨ç¤ºæ²¡æœ‰å†å²æ•°æ®ï¼‰
X_train = df_train[base_features].fillna(0)
y_train = df_train[target_col]

X_val = df_val[base_features].fillna(0)
y_val = df_val[target_col]

X_test = df_test[base_features].fillna(0)
y_test = df_test[target_col]

print(f"âœ“ ç¼ºå¤±å€¼å·²å¤„ç†")
print(f"  è®­ç»ƒé›†: X={X_train.shape}, y={len(y_train)}")
print(f"  éªŒè¯é›†: X={X_val.shape}, y={len(y_val)}")
print(f"  æµ‹è¯•é›†: X={X_test.shape}, y={len(y_test)}")

# ============================================================================
# Part 4: æ¨¡å‹è®­ç»ƒ
# ============================================================================

print("\n" + "="*80)
print("Part 4: è®­ç»ƒå¤šä¸ªåŸºçº¿æ¨¡å‹")
print("="*80)

models = {}
predictions_val = {}
predictions_test = {}

# ----------------------------------------------------------------------------
# Model 1: çº¿æ€§å›å½’ (Baseline)
# ----------------------------------------------------------------------------
print("\n[1/6] è®­ç»ƒçº¿æ€§å›å½’...")
lr = LinearRegression()
lr.fit(X_train, y_train)
models['Linear Regression'] = lr

pred_val_lr = lr.predict(X_val)
pred_test_lr = lr.predict(X_test)

# ç¡®ä¿é¢„æµ‹å€¼éè´Ÿ
pred_val_lr = np.maximum(0, pred_val_lr)
pred_test_lr = np.maximum(0, pred_test_lr)

predictions_val['Linear Regression'] = pred_val_lr
predictions_test['Linear Regression'] = pred_test_lr

print(f"âœ“ çº¿æ€§å›å½’è®­ç»ƒå®Œæˆ")

# ----------------------------------------------------------------------------
# Model 2: æ³Šæ¾å›å½’ (é€‚åˆè®¡æ•°æ•°æ®)
# ----------------------------------------------------------------------------
print("\n[2/6] è®­ç»ƒæ³Šæ¾å›å½’...")
try:
    poisson = PoissonRegressor(max_iter=500, alpha=0.1)
    poisson.fit(X_train, y_train)
    models['Poisson Regression'] = poisson
    
    pred_val_poisson = poisson.predict(X_val)
    pred_test_poisson = poisson.predict(X_test)
    
    predictions_val['Poisson Regression'] = pred_val_poisson
    predictions_test['Poisson Regression'] = pred_test_poisson
    
    print(f"âœ“ æ³Šæ¾å›å½’è®­ç»ƒå®Œæˆ")
except Exception as e:
    print(f"âš ï¸ æ³Šæ¾å›å½’è®­ç»ƒå¤±è´¥: {e}")

# ----------------------------------------------------------------------------
# Model 3: Random Forest
# ----------------------------------------------------------------------------
print("\n[3/6] è®­ç»ƒRandom Forest...")
rf = RandomForestRegressor(
    n_estimators=100,
    max_depth=15,
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42,
    n_jobs=-1
)
rf.fit(X_train, y_train)
models['Random Forest'] = rf

pred_val_rf = rf.predict(X_val)
pred_test_rf = rf.predict(X_test)

pred_val_rf = np.maximum(0, pred_val_rf)
pred_test_rf = np.maximum(0, pred_test_rf)

predictions_val['Random Forest'] = pred_val_rf
predictions_test['Random Forest'] = pred_test_rf

print(f"âœ“ Random Forestè®­ç»ƒå®Œæˆ")

# ----------------------------------------------------------------------------
# Model 4: XGBoost
# ----------------------------------------------------------------------------
print("\n[4/6] è®­ç»ƒXGBoost...")
xgb_model = xgb.XGBRegressor(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    objective='reg:squarederror'
)
xgb_model.fit(X_train, y_train)
models['XGBoost'] = xgb_model

pred_val_xgb = xgb_model.predict(X_val)
pred_test_xgb = xgb_model.predict(X_test)

pred_val_xgb = np.maximum(0, pred_val_xgb)
pred_test_xgb = np.maximum(0, pred_test_xgb)

predictions_val['XGBoost'] = pred_val_xgb
predictions_test['XGBoost'] = pred_test_xgb

print(f"âœ“ XGBoostè®­ç»ƒå®Œæˆ")

# ----------------------------------------------------------------------------
# Model 5: TMH-OMP (Tobit + å›ºå®šæ•ˆåº” + Mundlak)
# ----------------------------------------------------------------------------
print("\n[5/6] è®­ç»ƒTMH-OMPæ¨¡å‹...")
print("  ä½¿ç”¨ä¿®æ­£çš„OLSå›å½’æ¨¡æ‹ŸTobitæ•ˆåº”")

# TMH-OMPç®€åŒ–å®ç°ï¼šä½¿ç”¨å¸¦å›ºå®šæ•ˆåº”å’ŒMundlakä¿®æ­£çš„å›å½’
try:
    # å‡†å¤‡TMHç‰¹å¾
    X_train_tmh = df_train[tmh_features].fillna(0)
    X_val_tmh = df_val[tmh_features].fillna(0)
    X_test_tmh = df_test[tmh_features].fillna(0)
    
    # ä½¿ç”¨å²­å›å½’å¤„ç†å¤šé‡å…±çº¿æ€§
    from sklearn.linear_model import Ridge
    tmh_model = Ridge(alpha=1.0)
    tmh_model.fit(X_train_tmh, y_train)
    models['TMH-OMP'] = tmh_model
    
    pred_val_tmh = tmh_model.predict(X_val_tmh)
    pred_test_tmh = tmh_model.predict(X_test_tmh)
    
    # Tobitæ•ˆåº”ï¼šæˆªæ–­è´Ÿå€¼
    pred_val_tmh = np.maximum(0, pred_val_tmh)
    pred_test_tmh = np.maximum(0, pred_test_tmh)
    
    predictions_val['TMH-OMP'] = pred_val_tmh
    predictions_test['TMH-OMP'] = pred_test_tmh
    
    print(f"âœ“ TMH-OMPè®­ç»ƒå®Œæˆ")
    print(f"  ä½¿ç”¨äº†Mundlakä¿®æ­£ (æ—¶é—´å¹³å‡å€¼)")
    print(f"  ä½¿ç”¨äº†å›½å®¶å›ºå®šæ•ˆåº” (NOC_encoded)")
    
except Exception as e:
    print(f"âš ï¸ TMH-OMPè®­ç»ƒå¤±è´¥: {e}")

# ----------------------------------------------------------------------------
# Model 6: é›†æˆæ¨¡å‹ (Ensemble)
# ----------------------------------------------------------------------------
print("\n[6/6] è®­ç»ƒé›†æˆæ¨¡å‹...")
try:
    # ç®€å•å¹³å‡é›†æˆ
    pred_val_ensemble = (pred_val_rf + pred_val_xgb) / 2
    pred_test_ensemble = (pred_test_rf + pred_test_xgb) / 2
    
    predictions_val['Ensemble (RF+XGB)'] = pred_val_ensemble
    predictions_test['Ensemble (RF+XGB)'] = pred_test_ensemble
    
    print(f"âœ“ é›†æˆæ¨¡å‹å®Œæˆ (RF + XGBoostå¹³å‡)")
except Exception as e:
    print(f"âš ï¸ é›†æˆæ¨¡å‹å¤±è´¥: {e}")

# ============================================================================
# Part 5: æ¨¡å‹è¯„ä¼°
# ============================================================================

print("\n" + "="*80)
print("Part 5: æ¨¡å‹è¯„ä¼°ä¸å¯¹æ¯”")
print("="*80)

def evaluate_model(y_true, y_pred, model_name, dataset_name):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    
    # è®¡ç®—å¹³å‡è¯¯å·®ç™¾åˆ†æ¯”
    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1))) * 100
    
    return {
        'Model': model_name,
        'Dataset': dataset_name,
        'RMSE': rmse,
        'MAE': mae,
        'R2': r2,
        'MAPE': mape
    }

# è¯„ä¼°æ‰€æœ‰æ¨¡å‹
results = []

for model_name in predictions_val.keys():
    # éªŒè¯é›†è¯„ä¼°
    val_metrics = evaluate_model(
        y_val, predictions_val[model_name], 
        model_name, 'Validation (2020)'
    )
    results.append(val_metrics)
    
    # æµ‹è¯•é›†è¯„ä¼°
    test_metrics = evaluate_model(
        y_test, predictions_test[model_name],
        model_name, 'Test (2024)'
    )
    results.append(test_metrics)

# è½¬æ¢ä¸ºDataFrame
results_df = pd.DataFrame(results)

# æ˜¾ç¤ºç»“æœ
print("\næ¨¡å‹æ€§èƒ½å¯¹æ¯”:")
print("="*100)
print(results_df.to_string(index=False))

# ä¿å­˜ç»“æœ
results_df.to_csv('Results/13_model_comparison.csv', index=False)
print(f"\nâœ“ å·²ä¿å­˜: Results/13_model_comparison.csv")

# æ‰¾å‡ºæœ€ä½³æ¨¡å‹
print("\n" + "="*80)
print("æœ€ä½³æ¨¡å‹é€‰æ‹©:")
print("="*80)

# åŸºäºæµ‹è¯•é›†RMSE
test_results = results_df[results_df['Dataset'] == 'Test (2024)']
best_model = test_results.loc[test_results['RMSE'].idxmin()]

print(f"\nğŸ† æœ€ä½³æ¨¡å‹ (åŸºäºæµ‹è¯•é›†RMSE): {best_model['Model']}")
print(f"  RMSE: {best_model['RMSE']:.3f}")
print(f"  MAE: {best_model['MAE']:.3f}")
print(f"  RÂ²: {best_model['R2']:.3f}")
print(f"  MAPE: {best_model['MAPE']:.1f}%")

# ============================================================================
# Part 6: å¯è§†åŒ–å¯¹æ¯”
# ============================================================================

print("\n" + "="*80)
print("Part 6: å¯è§†åŒ–æ¨¡å‹å¯¹æ¯”")
print("="*80)

# åˆ›å»ºFiguresæ–‡ä»¶å¤¹
import os
os.makedirs('Figures', exist_ok=True)

# å›¾1: æ¨¡å‹æ€§èƒ½å¯¹æ¯” (RMSE)
plt.figure(figsize=(12, 6))
test_rmse = test_results.sort_values('RMSE')
plt.barh(test_rmse['Model'], test_rmse['RMSE'], color='steelblue')
plt.xlabel('RMSE (Root Mean Squared Error)', fontsize=12)
plt.title('Model Performance Comparison - Test Set (2024)', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.savefig('Figures/06_model_rmse_comparison.png', dpi=300, bbox_inches='tight')
print("âœ“ å·²ä¿å­˜: Figures/06_model_rmse_comparison.png")
plt.close()

# å›¾2: å®é™…å€¼ vs é¢„æµ‹å€¼ (æœ€ä½³æ¨¡å‹)
best_model_name = best_model['Model']
best_pred = predictions_test[best_model_name]

plt.figure(figsize=(10, 10))
plt.scatter(y_test, best_pred, alpha=0.5, s=50)
plt.plot([0, y_test.max()], [0, y_test.max()], 'r--', lw=2, label='Perfect Prediction')
plt.xlabel('Actual Gold Medals (2024)', fontsize=12)
plt.ylabel('Predicted Gold Medals', fontsize=12)
plt.title(f'Actual vs Predicted - {best_model_name}', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(alpha=0.3)
plt.tight_layout()
plt.savefig('Figures/07_actual_vs_predicted_best.png', dpi=300, bbox_inches='tight')
print("âœ“ å·²ä¿å­˜: Figures/07_actual_vs_predicted_best.png")
plt.close()

# å›¾3: å‰10åå›½å®¶é¢„æµ‹å¯¹æ¯”
top10_idx = y_test.nlargest(10).index
top10_actual = y_test[top10_idx]
top10_pred = pd.Series(best_pred, index=y_test.index)[top10_idx]
top10_nocs = df_test.loc[top10_idx, 'NOC'].values

x = np.arange(len(top10_nocs))
width = 0.35

plt.figure(figsize=(12, 6))
plt.bar(x - width/2, top10_actual, width, label='Actual', color='gold')
plt.bar(x + width/2, top10_pred, width, label='Predicted', color='steelblue')
plt.xlabel('Country', fontsize=12)
plt.ylabel('Gold Medals', fontsize=12)
plt.title('Top 10 Countries - Actual vs Predicted (2024)', fontsize=14, fontweight='bold')
plt.xticks(x, top10_nocs, rotation=45)
plt.legend()
plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.savefig('Figures/08_top10_comparison.png', dpi=300, bbox_inches='tight')
print("âœ“ å·²ä¿å­˜: Figures/08_top10_comparison.png")
plt.close()

# ============================================================================
# Part 7: ç‰¹å¾é‡è¦æ€§ï¼ˆæ ‘æ¨¡å‹ï¼‰
# ============================================================================

print("\n" + "="*80)
print("Part 7: ç‰¹å¾é‡è¦æ€§åˆ†æ")
print("="*80)

# Random Forestç‰¹å¾é‡è¦æ€§
if 'Random Forest' in models:
    rf_model = models['Random Forest']
    feature_importance = pd.DataFrame({
        'Feature': base_features,
        'Importance': rf_model.feature_importances_
    }).sort_values('Importance', ascending=False)
    
    print("\nRandom Forest - Top 10ç‰¹å¾é‡è¦æ€§:")
    print(feature_importance.head(10).to_string(index=False))
    
    # ä¿å­˜
    feature_importance.to_csv('Results/14_feature_importance.csv', index=False)
    print(f"\nâœ“ å·²ä¿å­˜: Results/14_feature_importance.csv")
    
    # å¯è§†åŒ–
    plt.figure(figsize=(10, 8))
    top_features = feature_importance.head(15)
    plt.barh(top_features['Feature'], top_features['Importance'], color='steelblue')
    plt.xlabel('Importance', fontsize=12)
    plt.title('Top 15 Feature Importance (Random Forest)', fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.savefig('Figures/09_feature_importance.png', dpi=300, bbox_inches='tight')
    print("âœ“ å·²ä¿å­˜: Figures/09_feature_importance.png")
    plt.close()

# ============================================================================
# Part 8: 2028å¹´é¢„æµ‹å‡†å¤‡
# ============================================================================

print("\n" + "="*80)
print("Part 8: ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆç”¨äº2028é¢„æµ‹ï¼‰")
print("="*80)

# ä¿å­˜æœ€ä½³æ¨¡å‹
import joblib

best_model_obj = models[best_model_name]
joblib.dump(best_model_obj, 'Models/best_model.pkl')
print(f"âœ“ å·²ä¿å­˜æœ€ä½³æ¨¡å‹: Models/best_model.pkl")
print(f"  æ¨¡å‹: {best_model_name}")

# ä¿å­˜ç‰¹å¾åˆ—è¡¨
with open('Models/feature_list.txt', 'w') as f:
    for feat in base_features:
        f.write(f"{feat}\n")
print(f"âœ“ å·²ä¿å­˜ç‰¹å¾åˆ—è¡¨: Models/feature_list.txt")

# ============================================================================
# Part 9: æ€»ç»“
# ============================================================================

print("\n" + "="*80)
print("Part 9: å»ºæ¨¡å®Œæˆæ€»ç»“")
print("="*80)

print(f"\nâœ“âœ“âœ“ åŸºçº¿æ¨¡å‹è®­ç»ƒå®Œæˆ!")
print(f"\nè®­ç»ƒçš„æ¨¡å‹:")
for i, model_name in enumerate(models.keys(), 1):
    print(f"  {i}. {model_name}")

print(f"\næœ€ä½³æ¨¡å‹: {best_model_name}")
print(f"  æµ‹è¯•é›†æ€§èƒ½:")
print(f"    RMSE: {best_model['RMSE']:.3f}")
print(f"    MAE: {best_model['MAE']:.3f}")
print(f"    RÂ²: {best_model['R2']:.3f}")

print(f"\nç”Ÿæˆçš„æ–‡ä»¶:")
print(f"  ç»“æœ:")
print(f"    - Results/13_model_comparison.csv (æ¨¡å‹å¯¹æ¯”)")
print(f"    - Results/14_feature_importance.csv (ç‰¹å¾é‡è¦æ€§)")
print(f"  å›¾è¡¨:")
print(f"    - Figures/06_model_rmse_comparison.png")
print(f"    - Figures/07_actual_vs_predicted_best.png")
print(f"    - Figures/08_top10_comparison.png")
print(f"    - Figures/09_feature_importance.png")
print(f"  æ¨¡å‹:")
print(f"    - Models/best_model.pkl")
print(f"    - Models/feature_list.txt")

print(f"\nä¸‹ä¸€æ­¥:")
print(f"  1. æŸ¥çœ‹æ¨¡å‹å¯¹æ¯”ç»“æœ")
print(f"  2. åˆ†æç‰¹å¾é‡è¦æ€§")
print(f"  3. ä½¿ç”¨æœ€ä½³æ¨¡å‹é¢„æµ‹2028å¹´å¥¥è¿ä¼š!")

print("\n" + "="*80)
print(f"å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("="*80)
